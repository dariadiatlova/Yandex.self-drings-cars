{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport random\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,TensorDataset, DataLoader\nfrom pytorch_lightning import metrics","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Введение\nВ данной работе предлагается построить классификатор состояний светофоров на основе свёрточной нейронной сети (CNN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_val_dir = '/kaggle/input/sirius-traffic-lights-competition/train_val'\ntrain_val_keys = pd.read_csv(os.path.join(train_val_dir, 'keys.csv'))","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FIXED_IMG_HEIGHT = 64\nFIXED_IMG_WIDTH = 64\n\ndef load_img(subset_dir, pic_id):\n    img = cv.imread(os.path.join(subset_dir, 'pic', pic_id + '.jpg'))\n    return cv.cvtColor(img, cv.COLOR_BGR2RGB)  # BGR -> RGB convertion\n\ndef resize_img(img, res_shape=(FIXED_IMG_HEIGHT, FIXED_IMG_WIDTH)):\n    height, width = img.shape[:2]\n    resized_width = int(res_shape[0] * (float(width) / height))\n    img_resized = cv.resize(img, (resized_width, int(res_shape[0])))\n    width_to_copy = min(resized_width, res_shape[1])\n    img_resized_filled_with_zero = np.zeros([res_shape[0], res_shape[1], 3], dtype=img.dtype)\n    img_resized_filled_with_zero[:, :width_to_copy, :] = img_resized[:, :width_to_copy, :]\n    return img_resized_filled_with_zero\n\ndef norm_img(img):\n    return (img.astype(np.float32) - 128.) / 255.","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загрузка train\\validation датасета"},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train_val = np.zeros([len(train_val_keys['id']), FIXED_IMG_HEIGHT, FIXED_IMG_WIDTH, 3], dtype=np.float32)\nfor idx, pic_id in tqdm(enumerate(train_val_keys['id'])):\n    images_train_val[idx] = norm_img(resize_img(load_img(train_val_dir, pic_id)))","execution_count":5,"outputs":[{"output_type":"stream","text":"45633it [07:54, 96.07it/s] \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl_states = np.unique(train_val_keys['category'])\nprint(tl_states)","execution_count":6,"outputs":[{"output_type":"stream","text":"['disabled' 'green' 'red' 'red_yellow' 'yellow']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train_val = np.zeros(len(train_val_keys), dtype=np.int)\nfor idx, state in enumerate(tl_states):\n    labels_train_val[train_val_keys['category'] == state] = idx\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разобъем датасет на train/validation в соотношении 4/1"},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_categorical(y, num_classes):\n    return np.eye(num_classes, dtype='uint8')[y]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(tl_states)\nval_samples_num = int(len(images_train_val) * 0.2)\nimages_val = images_train_val[:val_samples_num]\nlabels_val = labels_train_val[:val_samples_num]\ny_val = to_categorical(labels_val, num_classes)\n\nimages_train = images_train_val[val_samples_num:]\nlabels_train = labels_train_val[val_samples_num:]\ny_train = to_categorical(labels_train, num_classes)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sum(y_val, axis=0))\nprint(np.sum(y_train, axis=0))\nprint(y_val.shape, images_val.shape)\nprint(y_train.shape, images_train.shape)\nprint(f'size of train dataset: {len(y_train)}, size of validation dataset: {len(y_val)}')","execution_count":10,"outputs":[{"output_type":"stream","text":"[ 974 3162 4089  419  482]\n[ 3614 12898 16561  1622  1812]\n(9126, 5) (9126, 64, 64, 3)\n(36507, 5) (36507, 64, 64, 3)\nsize of train dataset: 36507, size of validation dataset: 9126\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Задание 1\nНеоходимо создать модель CNN (Convolutional Neural Network), состоящей из нескольких последовательных сверточных слоев. Между сверточными слоями целесообразно добавить несколько max-pooling слев для увеличения receptive field. В самом конце необходимо добавить полносвязный слой (dense), размер выхода которого совпадает с количеством классов (в нашем случае 5).\n\nВ данной работе используется библиотеки  tensorflow + keras для формирования и обучения модели, однако такой выбор не является обязательным.\n\nНиже приведен пример шаблона для такой нейронной сети. Целевой функцией потерь была выбрана бинарная кросс-энтропия, что является класическим выбором при решении задачи классификации. Стоит обратить внимание на параметр from_logits=True, указывающий на то что в качестве выхода нейронная сеть будет выдавать \"сырые\" значения в диапазоне  $(-\\inf; +\\inf)$ а не вероятности (в противном случае последним слоем нейронной сети должен быть soft-max)."},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nimages_train = torch.tensor(images_train).to(device)\nimages_val = torch.tensor(images_val).to(device)\ny_train = torch.tensor(y_train).to(device)\ny_val = torch.tensor(y_val).to(device)\n\nbatch_size = 128\n\ndata_train = TensorDataset(images_train, y_train)\ndata_val = TensorDataset(images_val, y_val)\n\ndata_loader_train = DataLoader(data_train, shuffle=True, batch_size=batch_size)\ndata_loader_val = DataLoader(data_train, shuffle=True, batch_size=batch_size)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):    \n    \n    def __init__(self, channels=8, latent_size=64, samplings=4, out_channels=5):       \n        super().__init__() \n        modules = [nn.Conv2d(latent_size, channels, kernel_size=1, stride=1, padding=0)]\n        for i in range(samplings):\n            channels *= 2\n            modules += [nn.Conv2d(channels//2, channels, kernel_size=3, stride=2, padding=1),\n                           nn.BatchNorm2d(channels),\n                           nn.ReLU()]\n        modules += [nn.Conv2d(channels, channels*2, kernel_size=3, stride=2, padding=1),\n                   nn.Dropout(p=0.2),\n                   nn.Flatten(),\n                   nn.Linear(channels*4, out_channels)]\n        self.layers = nn.Sequential(*modules)\n\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:   \n        return self.layers(x)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Задание 2\n\nОбучите модель и оцените её точность как на train, так и на validation подмножествах.\n\nПопробуйте варьировать кол-во слоёв, их размер, а также параметры обучения. Необходимо получить точность > 90% на валидационном подмножестве."},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n    predictions = model.forward(X)\n    loss = nn.BCEWithLogitsLoss()\n    return loss(predictions, y.type_as(predictions))\n\ndef train(model: Model, max_epochs=101):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    train_accuracy = metrics.Accuracy().to(device)\n    valid_accuracy = metrics.Accuracy(compute_on_step=False).to(device)\n    for epoch in range(max_epochs):       \n        # Train\n        for X, y in data_loader_train:\n            y_hat = model(X)\n            batch_acc = train_accuracy(y_hat, y)\n            loss = calculate_loss(X, y, model)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step() \n        # Val  \n        with torch.set_grad_enabled(False):         \n            for X, y in data_loader_val:\n                y_hat = model(X)\n                valid_accuracy(y_hat, y)\n                loss = calculate_loss(X, y, model)\n        total_train_accuracy = train_accuracy.compute()\n        total_valid_accuracy = valid_accuracy.compute()\n        if epoch % 10 == 0:\n            print(f\"Epoch: {epoch}, | Train accuracy: {total_train_accuracy}, Validation accuracy, {total_valid_accuracy}\")                 \n    return \n                  \nmodel = Model()\nmodel.to(device)\ntrain(model)","execution_count":18,"outputs":[{"output_type":"stream","text":"Epoch: 0, | Train accuracy: 0.8711151480674744, Validation accuracy, 0.8976853489875793\nEpoch: 10, | Train accuracy: 0.9592516422271729, Validation accuracy, 0.9609718918800354\nEpoch: 20, | Train accuracy: 0.9713588953018188, Validation accuracy, 0.973626971244812\nEpoch: 30, | Train accuracy: 0.975506067276001, Validation accuracy, 0.9789684414863586\nEpoch: 40, | Train accuracy: 0.9806831479072571, Validation accuracy, 0.9795053005218506\nEpoch: 50, | Train accuracy: 0.9829950332641602, Validation accuracy, 0.9846440553665161\nEpoch: 60, | Train accuracy: 0.9850330352783203, Validation accuracy, 0.9871860146522522\nEpoch: 70, | Train accuracy: 0.9863149523735046, Validation accuracy, 0.9876845479011536\nEpoch: 80, | Train accuracy: 0.9876571893692017, Validation accuracy, 0.9881502389907837\nEpoch: 90, | Train accuracy: 0.9886049032211304, Validation accuracy, 0.9912619590759277\nEpoch: 100, | Train accuracy: 0.9895581603050232, Validation accuracy, 0.991311252117157\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}